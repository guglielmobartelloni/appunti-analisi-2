\documentclass[../appunti-analisi.tex]{subfiles}

\begin{document}

\section{Lezione 20}

\teorema{Schwarz}{ Sia $f: A \subseteq \mathbb{R}^{n} \rightarrow \mathbb{R}$, $A$ aperto

    e supponiamo che la $f$ sia derivabile due volte su $A$, quindi esistono tutte le $f_{x_i x_j}$, $\forall i,j=1,\ldots,n$ e sia $\bar{x_0} \in A$.


    Se le $f_{x_i x_j}$, e le $f_{x_j x_i}$ con $i \neq j$ sono \textbf{continue}  in $x_0$, allora:

    \[
        f_{x_i x_j}(x_0) = f_{x_j x_i}(x_0)
    \]

}


\textbf{Caso $n=2$}


$f: A \subseteq \mathbb{R}^{2} \rightarrow \mathbb{R}$, $P_0=(x_0,y_0) \in A$


$f$ derivabile due volte su $A$ (quindi esiste la matrice Hessiana).


Se le $f_{xy}$ e $f_{yx}$ sono continue in $(x_0,y_0)$, allora $f_{xy}(x_0,y_0) = f_{yx}(x_0,y_0)$ (la matrice Hessiana è simmetrica).


\begin{proof}
       Sia $P_0=(x_0,y_0)$ e $P=(x,y)$ un punto qualsiasi su $A$, con $P \neq P_0$ (quindi $x \neq x_0, y \neq y_0$)

       Consideriamo il valore della funzione nei punti:

       \[
           f(x_0,y_0) = f(x,y_0), f(x,y), f(x_0,y)
       \]

       \[
           \underbrace{F(x)}_\text{dipende solo da $x$ ($y$ fissato)} = f(x,y) - f(x,y_0)
       \]

       \[
           \underbrace{G(y)}_\text{dipende solo da $y$ ($x$ fissato)}  = f(x,y) - f(x_0,y)
       \]

       Applico il teorema di Lagrange (teorema del valore intermedio)

       Lagrange a $F(x)$ nell'intervallo di estremi $x_0$, $x$, si ha che esiste un elemento $x_1$ in questo intervallo per cui:

       \[
           F(x)- F(x_0) = F'(x_1) (x-x_0) = [f_x(x_1,y) - f_x(x_1,y_0) ] (x- x_0)  \overset{\text{applico Lagrange due volte come spiegato sotto}}{=}
       \]

       Sappiamo che $f$ è derivabile due volte, posso quindi applicare Lagrange a $f_x(x_1,y)$ nell'intervallo di estremi $y_0,y$. Quindi $\exists y_1$ nell'intervallo tale che:

       \[
           f_x(x_1,y) - f_x(x_1,y_0) = \frac{\partial }{\partial y}(f_x(x_1,y_1))(y-y_0) = f_{xy}(x_1,y_1)(y-y_0)
       \]

       quindi la nostra espressione diventa:

       \[
           = f_{xy}(x_1,y_1)(x-x_0) (y-y_0)
       \]

       quindi abbiamo fatto vedere che:

       \[
           F(x) -F(x_0) = f_{xy}(x_1,y_1) (x-x_0)(y-y_0)
       \]

       Analogamente per $G(y)$ applico Lagrange quindi $\exists y_2$ nell'intervallo di estremi $y,y_0$ tale che:

       \[
           G(y) -G(y_0) = G'(y_2) (y-y_0) = [f_y(x,y_2) - f_y(x_0,y_2)] (y-y_0) \overset{\text{applico di nuovo Lagrange}}{=}
       \]

       applico quindi Lagrange a $f_y(x,y_2)$ nell'intervallo di estremi $x,x_0$ quindi $\exists x_2$ in questo intervallo:

       \[
           f_y(x,y_2) - f_y(x_0,y_2) = f_{yx}(x_2,y_2)(x-x_0)
       \]

       infine quindi:

       \[
           = f_{yx}(x_2,y_2)(x-x_0)(y-y_0)
       \]


       Notiamo che:

       \[
           F(x) - F(x_0) = G(y) -G(y_0)
       \]

       \[
           G(y) - G(y_0) = f(x,y) - f(x_0,y) - (f(x,y_0) -f(x_0,y_0))
       \] 

       \[
           F(x) - F(x_0) = f(x,y) - f(x_0,y) - (f(x,y_0) -f(x_0,y_0))
       \] 

       Le due espressioni sono quindi uguali (ho sostituito alle definizioni iniziali delle funzioni), di conseguenza anche le espressioni ottenute precedentemente

       Essendo $F(x) - F(x_0) = G(y) - G(y_0)$, segue che:

       \[
           f_{xy}(x_1,y_1)(x-x_0)(y-y_0) = f_{yx}(x_2,y_2)(x-x_0)(y-y_0)
       \]

       noi sappiamo che $(x,y) \neq (x_0,y_0)$ per ipotesi (dato che $P \neq P_0$), quindi deve essere che:

       \[
           f_{xy}(x_1,y_1) = f_{yx}(x_2,y_2)
       \]

       $(x_1,y_1)$ e $(x_2,y_2)$ stanno nell'intervallo del rettangolo tratteggiato:


       \begin{center}
       \begin{tikzpicture}
           \draw[->] (-3, 0) -- (4.2, 0) node[right] {$x$};
           \draw[->] (0, -3) -- (0, 4.2) node[above] {$y$};
           \draw[densely dotted] (1,1) -- (2,1) node[right] {$P_0$};
           \draw[densely dotted] (1,1) -- (1,2);
           \draw[densely dotted] (2,1) -- (2,2);
           \draw[densely dotted] (1,2) -- (2,2);
       \end{tikzpicture}
       \end{center}

       Passando al limite (per $P \rightarrow P_0$) succede che:

       \[
           (x,y) \rightarrow (x_0,y_0)
       \]

       \[
           (x,y_0) \rightarrow (x_0,y_0)
       \]

       \[
           (x_2,y_2) \rightarrow (x_0,y_0)
       \]

       ed essendo la funzione $f_{xy},f_{yx}$ continue in $P_0=(x_0,y_0)$, si ha:

       \[
           f_{xy}(x_0,y_0) = f_{yx}(x_0,y_0)
       \]


\end{proof}

\begin{proof} \textbf{Alternativa con integrali doppi} 
    
    Sia un generico rettangolo $R = [a,b]\times [c,d]$

    Integro $f_{xy}(x,y)$:

    \[
        \int_{c}^{d} {\int_{a}^{b} {f_{yx}(x,y)} \: dx } \: d y \overset{\text{separo la doppia derivata}}{=} \int_{c}^{d} {\int_{a}^{b} {(f_y(x,y))_x} \: dx } \: dy=
    \]

    \[
        = \int_{c}^{d} {f_y(b,y) - f_y(a,y)} \: d y = f(b,d) - f(b,c) - f(a,d) + f(a,c)
    \]

    Adesso vediamo l'altro integrale di $f_{yx}(x,y)$ (si inverte l'integrale con il teorema di Fubini che presuppone che la funzione sia continua):

    \[
        \int_{c}^{d} {\int_{a}^{b} {f_{xy}} \: dx } \: d y \overset{\text{Teorema di Fubini}}{=} \int_{a}^{b} {\int_{c}^{d} {(f_x)_y} \: d y } \: dx =
    \]

    \[
        =\int_{a}^{b} {f_x(x,d) - f_x(x,c)} \: dx  = f(b,d) - f(a,d) - f(b,c) + f(a,c)
    \]

    e quindi $f_{xy}(x,y) = f_{yx}(x,y)$:

    \[
      f(b,d) - f(b,c) - f(a,d) + f(a,c) = f(b,d) - f(a,d) - f(b,c) + f(a,c)
    \]

    Questo funziona per ogni rettangolo che pongo infatti:

    \[
        \int_{c}^{d} {\int_{a}^{b} {f_{yx}} \: dx } \: d y =  \int_{c}^{d} {\int_{a}^{b} {f_{xy}} \: dx } \: d y 
    \]

    Quindi la loro differenza deve essere 0:

    \[
        \iint_R \underbrace{{(f_{yx} - f_{xy})}}_\text{continue} \: dx d y = 0
    \]

    Vale perché essendo le funzioni continue se supponiamo per assurdo che la differenza sia positiva in un certo punto $x_0$ allora la funzione è positiva anche in un piccolo rettangolo intorno a quel punto (per la continuità) ma questo è assurdo perché nel rettangolo la differenza delle due funzioni è 0.

    Quindi proprio per il fatto che le funzioni sono continue allora questo teorema funziona.

\end{proof}



\textbf{Esempio} 

\[
f(x,y)=\begin{cases}
    0 & \text{se $(x,y) = (0,0)$} \\
    \frac{x^{3}-xy^{3}}{x^{2}+y^{2}} & \text{se $(x,y) \neq (0,0)$}
\end{cases}
\]

$f: \mathbb{R}^{2} \rightarrow \mathbb{R}$ 

Si verifica che $f(x,y)$ è continua in $(0,0)$ (passando dalle coordinate polari):

\[
    \lim_{ (x,y) \to (0,0) } f(x,y)=f(0,0) = 0
\]

e che le funzioni $f_x(x,y)$ e $f_y(x,y)$ sono anch'esse continue in $(0,0)$

Se $(x,y) \neq (0,0)$:

\[
    f_x(x,y) = \frac{(3x^{2}y-y^{3})(x^{2}+y^{2})-2x(x^{3}y-xy^{3})}{(x^{2}+y^{2})^{2}} = 3x^{4}y+3x^{2}y^{3}-x^{2}y^{3}-x^{2}y^{3}-y^{5}-2x^{4}y+2x^{2}y^{3} 
\]


$\forall (x,y) \neq (0,0)$ si ha che:

\[
f_x(x,y) = \frac{x^{4}y+4x^{2}y^{3}-y^{5}}{(x^{2}+y^{2})^{2}}
\]


In $(0,0)$:

\[
    \lim_{ h \to 0 } \frac{f(0+h,0) - f(0,0)}{h} = \lim_{ h \to 0 } \frac{h^{3}(0) - h\cdot 0}{h^{2}+0} \cdot  \frac{1}{h} = 0
\]


Derivata seconda in $(0,0)$:

\[
    f_{xy} (0,0) \overset{\text{limite se esiste}}{=} \lim_{ k \to 0 } \frac{f_x(0,0+k) - f_x(0,0)}{k} = \lim_{ k \to 0 } \frac{ \frac{-k^{5}}{k^{4}}}{k} = -1
\]

OSS: $f(x,y)=-f(y,x)$, quindi:

\[
    f_{yx}(0,0) = \underbrace{-(-1)}_\text{$-f_{xy}(0,0)$} = 1
\]

Se le derivate seconde sono diverse allora per Schwarz le derivate non sono continue in $(0,0)$ come in questo caso.



Se $f \in \mathbb{C}^{(2)} (A) \xrightarrow[]{\text{Shwarz}} f_{xy}(x,y) = f_yx(x,y)$ $\forall (x,y) \in A$, inoltre $H f(x,y)$ è simmetrica $\forall (x,y) \in A$ (quindi $Hf(x,y)^{T}=Hf(x,y)$)

Se $f \in \mathbb{C}^{k}(A)$ allora l'ordine di derivazione non conta sulle derivate parziali fino all'ordine k.

\subsection{Accenni per Taylor in più variabili}

$A \subseteq \mathbb{R}^{n}$ con $A$ aperto e $f:A \subseteq \mathbb{R}^{n} \rightarrow \mathbb{R}$ di classe $\mathbb{C}^{k}$ per qualche $k \in \mathbb{N}$ (regolare di regolarità k).

Siano $\bar{x}$ e $\bar{x} +\bar{h} $ due punti in $A$ tali che il segmento (di $\mathbb{R}^{n}$) che ha come estremi $\bar{x} $ e $\bar{x} + \bar{h} $, indicato con $[\bar{x} +\bar{x} +\bar{h} ] \subset \mathbb{R}^{n}$, sia tutto contenuto in $A$.

       \[
           [\bar{x} , \bar{x} +\bar{h} ] = \{\bar{x} (t) \in \mathbb{R}^{n}, \bar{x} (t) = \bar{x} +\bar{th}, t \in [0,1]\} \subset \mathbb{R}^{n}
       \]

       Consideriamo $f \in \mathbb{C}^{1}$ e 

       \[
           F(t) = f(x(t)) = f(\bar{x} +\bar{th} ) 
       \]

       $\forall t \in [0,1]$ $t \rightarrow  \bar{x} (t) = \bar{x} + \bar{th} \xrightarrow[]{\text{$f$}}f(\bar{x} (t))$

       \[
           F'(t) \overset{\text{regola della catena}}{=} \langle \nabla f(\bar{x} +\bar{th} ),\bar{h}  \rangle = \sum^{n}_{i=1} \frac{\partial f}{\partial x_i} (\bar{x} +\bar{th} ) h_i
       \]

       Se $f \in  \mathbb{C}^{2}$:

       \[
           F''(t) = (F'(t))' \overset{\text{regola della catena ancora}}{=} \sum^{n}_{j=1} \frac{\partial f}{\partial x_j} ( \frac{\partial f}{\partial x_i}(\bar{x} +\bar{th} ) h_i) h_j = \sum^{n}_{i,j=1} \frac{\partial^{2} f}{\partial x_i \partial x_j} (\bar{x} + \bar{th} ) h_i h_j
       \]

       Questo è un polinomio quadratico.
\end{document}
